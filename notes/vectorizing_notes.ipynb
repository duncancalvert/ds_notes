{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [General Vocabulary](#general-vocabulary)\n",
    "2. [Feature Engineering](#feature-engineering)\n",
    "    1. [One Hot Encoding](#one-hot-encoding)\n",
    "    2. [Bag of Words](#bag-of-words-bow)\n",
    "    3. [NGrams](#ngrams)\n",
    "    4. [TF-IDF](#tf-idf)\n",
    "    5. [Word Embeddings](#word-embeddings)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Vocabulary\n",
    "\n",
    "* <ins>Corpus</ins>: All words in a dataset\n",
    "* <ins>Vocabulary</ins>: Unique words in a dataset\n",
    "* <ins>Document</ins>: a single unique record in a dataset\n",
    "* <ins>Word</ins>: a single word in a document\n",
    "\n",
    "To better exemplify these concepts, let's use the following example dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# \n",
    "data = {\n",
    "    'Documents': [\n",
    "        'I love machine learning and data science',\n",
    "        'Data science is fascinating and challenging',\n",
    "        'Machine learning is a subset of data science',\n",
    "        'I enjoy learning new things in data science',\n",
    "        'This is an example document, it may have a lot of symbols like (! @ # $ or %)'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Convert the corpus (data dictionary) into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love machine learning and data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data science is fascinating and challenging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning is a subset of data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I enjoy learning new things in data science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is an example document, it may have a lot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Documents\n",
       "0           I love machine learning and data science\n",
       "1        Data science is fascinating and challenging\n",
       "2       Machine learning is a subset of data science\n",
       "3        I enjoy learning new things in data science\n",
       "4  This is an example document, it may have a lot..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Pre-process each document (row of the dataframe) to make it lowercase and split it into individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [i, love, machine, learning, and, data, science]\n",
      "1    [data, science, is, fascinating, and, challeng...\n",
      "2    [machine, learning, is, a, subset, of, data, s...\n",
      "3    [i, enjoy, learning, new, things, in, data, sc...\n",
      "4    [this, is, an, example, document,, it, may, ha...\n",
      "Name: Documents, dtype: object\n"
     ]
    }
   ],
   "source": [
    "corpus = df['Documents'].apply(lambda x: x.lower().split())\n",
    "print(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create a vocabulary of unique words from the corpus by turning it into a \"set\" and flatten the list of lists into a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set(word for document in corpus for word in document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's a set we can't use slicing. Instead let's print out the first 5 elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- A few random vocabulary words ---\n",
      "a\n",
      "subset\n",
      "in\n",
      "@\n",
      "learning\n"
     ]
    }
   ],
   "source": [
    "print(\"--- A few random vocabulary words ---\")\n",
    "for i, val in enumerate(itertools.islice(vocabulary, 5)):\n",
    "    print(val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check the total length to get the vocabulary size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total vocabulary size is 33 unqiue words/tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"The total vocabulary size is {} unqiue words/tokens\".format(len(vocabulary)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature Engineering, also known as \"feature extraction\", \"text representation\", or \"text vectorization\" is an integral step that allows us to represent text as numbers (feature vectors). This is required when working on NLP problem as computers can only understand numbers, not text in its raw form. Various approaches are covered below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "<ins>One Hot Encoding (OHE)</ins>: is used with categorical and natural language datasets to convert their values into 2-dimensional vector representations. Specifically, it functions by representing each category in a feature as a binary vector of 1s and 0s, with the vector's size equivalent to the number of potential categories (i.e. Vocabulary size in the case of natural language)\n",
    "\n",
    "Using the same example data set as before, let's create a list of all unique words to use as features for one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>subset</th>\n",
       "      <th>in</th>\n",
       "      <th>@</th>\n",
       "      <th>learning</th>\n",
       "      <th>it</th>\n",
       "      <th>i</th>\n",
       "      <th>and</th>\n",
       "      <th>fascinating</th>\n",
       "      <th>love</th>\n",
       "      <th>...</th>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <th>this</th>\n",
       "      <th>science</th>\n",
       "      <th>%)</th>\n",
       "      <th>an</th>\n",
       "      <th>document,</th>\n",
       "      <th>have</th>\n",
       "      <th>of</th>\n",
       "      <th>(!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  subset  in  @  learning  it  i  and  fascinating  love  ...  is  like  \\\n",
       "0  0       0   0  0         0   0  0    0            0     0  ...   0     0   \n",
       "1  0       0   0  0         0   0  0    0            0     0  ...   0     0   \n",
       "2  0       0   0  0         0   0  0    0            0     0  ...   0     0   \n",
       "3  0       0   0  0         0   0  0    0            0     0  ...   0     0   \n",
       "4  0       0   0  0         0   0  0    0            0     0  ...   0     0   \n",
       "\n",
       "   this  science  %)  an  document,  have  of  (!  \n",
       "0     0        0   0   0          0     0   0   0  \n",
       "1     0        0   0   0          0     0   0   0  \n",
       "2     0        0   0   0          0     0   0   0  \n",
       "3     0        0   0   0          0     0   0   0  \n",
       "4     0        0   0   0          0     0   0   0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the set into list\n",
    "vocabulary_list = list(vocabulary)\n",
    "\n",
    "# Create a DataFrame to hold the one-hot encoded representation\n",
    "one_hot_encoded_df = pd.DataFrame(0, index=range(len(df)), columns=vocabulary_list)\n",
    "one_hot_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoded DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>subset</th>\n",
       "      <th>in</th>\n",
       "      <th>@</th>\n",
       "      <th>learning</th>\n",
       "      <th>it</th>\n",
       "      <th>i</th>\n",
       "      <th>and</th>\n",
       "      <th>fascinating</th>\n",
       "      <th>love</th>\n",
       "      <th>...</th>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <th>this</th>\n",
       "      <th>science</th>\n",
       "      <th>%)</th>\n",
       "      <th>an</th>\n",
       "      <th>document,</th>\n",
       "      <th>have</th>\n",
       "      <th>of</th>\n",
       "      <th>(!</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  subset  in  @  learning  it  i  and  fascinating  love  ...  is  like  \\\n",
       "0  0       0   0  0         1   0  1    1            0     1  ...   0     0   \n",
       "1  0       0   0  0         0   0  0    1            1     0  ...   1     0   \n",
       "2  1       1   0  0         1   0  0    0            0     0  ...   1     0   \n",
       "3  0       0   1  0         1   0  1    0            0     0  ...   0     0   \n",
       "4  1       0   0  1         0   1  0    0            0     0  ...   1     1   \n",
       "\n",
       "   this  science  %)  an  document,  have  of  (!  \n",
       "0     0        1   0   0          0     0   0   0  \n",
       "1     0        1   0   0          0     0   0   0  \n",
       "2     0        1   0   0          0     0   1   0  \n",
       "3     0        1   0   0          0     0   0   0  \n",
       "4     1        0   1   1          1     1   1   1  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over each document and set the corresponding word column to 1\n",
    "for idx, document in enumerate(corpus):\n",
    "    for word in document:\n",
    "        one_hot_encoded_df.at[idx, word] = 1\n",
    "\n",
    "print(\"One-Hot Encoded DataFrame:\")\n",
    "one_hot_encoded_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words (BoW)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGrams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
