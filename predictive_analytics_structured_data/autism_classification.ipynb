{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autism Classification With Structured Data\n",
    "\n",
    "* <ins>Author</ins>: Duncan Calvert\n",
    "* <ins>Last Modified</ins>: 9/24/24\n",
    "\n",
    "This article is part of my series Watch One, Do One, Teach One (WDT), A data science series focused around helping beginner data scientist learn AI concepts, practice implementing them, and then teach the concept to others in order to cement their understanding. \n",
    "\n",
    "This specific template is meant to be used for ML classification with structured data sets. It has the following sections\n",
    "\n",
    "## Table of Contents\n",
    "1. [Library Imports](#1-package-imports-and-installs)\n",
    "2. [Configurations](#2-configurations)\n",
    "3. [Downloading the Data Set](#3-downloading-the-data-set)\n",
    "4. [Exploratory Data Analysis](#exploratory-data-analysis)\n",
    "    - [4a. Pandas EDA](#4a-pandas-eda)\n",
    "    - [4b. Check for Target Leakage](#4b-check-for-target-leakage)\n",
    "    - [4c. AutoViz](#4c-autoviz)\n",
    "5. [Data Cleaning](#5-data-cleaning)\n",
    "6. [Feature Engineering](#6-feature-engineering)\n",
    "7. [AutoML](#7-automl)\n",
    "8. [Iterative Modeling and Hyperparameter Tuning](#8-iterative-modeling-and-hyperparameter-tuning)\n",
    "9. [Explainability](#9-explainability)\n",
    "    - [9a. Feature Importance](#9a-feature-importance)\n",
    "    - [9b. Partial Dependence Plot](#9b-partial-dependence-plots)\n",
    "10. [Summary and Lessons Learned](#10-summary-and-lessons-learned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Package Imports and Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Imports\n",
    "from palmerpenguins import load_penguins\n",
    "\n",
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# AutoEDA Tools\n",
    "from autoviz import AutoViz_Class\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Feature Importance/Explainability:\n",
    "# import eli5\n",
    "# from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the max column count, allowing us to control truncation and visibility\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "# allows the dataframe to stretch across multiple pages\n",
    "pd.set_option('display.expand_frame_repr', False) \n",
    "\n",
    "# sets the maximum width of columns, allowing us to control visibility\n",
    "pd.set_option('max_colwidth', None) \n",
    "\n",
    "# display numbers to a higher precision\n",
    "pd.options.display.float_format = '{:,.7}'.format "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Downloading the Data Set\n",
    "\n",
    "#### Loading a toy data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the toy pandas data set from the palmerpenguins package\n",
    "# df = load_penguins()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/attis/Desktop/Autism-prediction/train.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading an Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pandas.read_excel('<Insert Excel File Name>.xlsx',sheet_name = '<Insert tab name>')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "file_path = \"/home/jupyter/data/news/news_some_company.json\"\n",
    "df = pd.read_json(file_path, orient='records', lines=True)\n",
    "df.head()\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading a Google Drive File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\n\\n# Mount Google Drive\\ndrive.mount('/content/drive')\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy files to local FS from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# GCS download function\n",
    "def get_gcs_data(bucket_name, folder_name, file_name, path_local):\n",
    "    url = 'https://storage.googleapis.com/' + bucket_name + '/' + folder_name + '/' + file_name\n",
    "    r = requests.get(url)\n",
    "    open(path_local + '/' + file_name , 'wb').write(r.content)\n",
    "\n",
    "# Receiving path\n",
    "path_news = '/home/jupyter/data/news'\n",
    "os.makedirs(path_news, exist_ok=True)\n",
    "    \n",
    "# GCS bucket details\n",
    "bucket_name = 'msca-bdp-data-open'\n",
    "folder_name = 'news'\n",
    "file_name = ['news_some_company.json']\n",
    "path_local = path_news\n",
    "\n",
    "os.makedirs(path_local, exist_ok=True)\n",
    "\n",
    "for file in file_name:\n",
    "    get_gcs_data (bucket_name = bucket_name,\n",
    "                 folder_name = folder_name,\n",
    "                 file_name = file,\n",
    "                 path_local = path_local)\n",
    "    print('Downloaded: ' + file)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA is one of the most important parts of any data science workflow as understanding the nuances of your data, identifying potential biases, missing data, or issues with your data set is extremely important for all subsequent steps. \n",
    "\n",
    "* <ins>Note</ins>: Even before EDA, whenever possible, you should attempt to discuss any potential data quality, availability, or bias issue with any data subject matter experts that are available. This is important as there are often nuances and potential pitfalls in the way data is collected and cataloged that may not be apparent from code-based EDA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Pandas EDA\n",
    "\n",
    "#### Shape\n",
    "The \"shape\" attribute gives the axis dimensions of the object, consistent with ndarray allowing us to quickly guage the size of our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 22)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Head/Tail\n",
    "The \"head\" and \"tail\" methods allow us to view a small sample of a Series or DataFrame object with the default length being 5. You can pass a parameter to the methods to increase/decrease their row count. These methods allow us to quickly get a sense of the columns/features available and what a few examples of the data set look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.6054</td>\n",
       "      <td>f</td>\n",
       "      <td>White-European</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>7.819715</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.82937</td>\n",
       "      <td>f</td>\n",
       "      <td>South Asian</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>Australia</td>\n",
       "      <td>no</td>\n",
       "      <td>10.5443</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  A8_Score  A9_Score  A10_Score    age   gender    ethnicity    jaundice austim contry_of_res  used_app_before  result    age_desc   relation  Class/ASD\n",
       "0   1      1         0         1         1         1         1         0         1         1         1      18.6054    f    White-European    no      no    United States        no       7.819715  18 and more   Self        0    \n",
       "1   2      0         0         0         0         0         0         0         0         0         1     13.82937    f       South Asian    no      no        Australia        no        10.5443  18 and more      ?        0    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jaundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.24147</td>\n",
       "      <td>f</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>3.682732</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Relative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.1701</td>\n",
       "      <td>f</td>\n",
       "      <td>Asian</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>no</td>\n",
       "      <td>12.06017</td>\n",
       "      <td>18 and more</td>\n",
       "      <td>Self</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID   A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  A8_Score  A9_Score  A10_Score    age   gender    ethnicity     jaundice austim contry_of_res  used_app_before  result    age_desc    relation  Class/ASD\n",
       "798  799      1         1         1         1         1         1         0         1         1         1     19.24147    f    Middle Eastern     no      yes   United States        no       3.682732  18 and more  Relative      0    \n",
       "799  800      1         0         0         1         1         0         0         1         1         1      32.1701    f              Asian    no       no     New Zealand        no       12.06017  18 and more      Self      0    "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info\n",
    "The \"info\" method provides us with column level info on our dataframe, specifically data types, null count, and indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               800 non-null    int64  \n",
      " 1   A1_Score         800 non-null    int64  \n",
      " 2   A2_Score         800 non-null    int64  \n",
      " 3   A3_Score         800 non-null    int64  \n",
      " 4   A4_Score         800 non-null    int64  \n",
      " 5   A5_Score         800 non-null    int64  \n",
      " 6   A6_Score         800 non-null    int64  \n",
      " 7   A7_Score         800 non-null    int64  \n",
      " 8   A8_Score         800 non-null    int64  \n",
      " 9   A9_Score         800 non-null    int64  \n",
      " 10  A10_Score        800 non-null    int64  \n",
      " 11  age              800 non-null    float64\n",
      " 12  gender           800 non-null    object \n",
      " 13  ethnicity        800 non-null    object \n",
      " 14  jaundice         800 non-null    object \n",
      " 15  austim           800 non-null    object \n",
      " 16  contry_of_res    800 non-null    object \n",
      " 17  used_app_before  800 non-null    object \n",
      " 18  result           800 non-null    float64\n",
      " 19  age_desc         800 non-null    object \n",
      " 20  relation         800 non-null    object \n",
      " 21  Class/ASD        800 non-null    int64  \n",
      "dtypes: float64(2), int64(12), object(8)\n",
      "memory usage: 137.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe\n",
    "The \"describe\" method provides common summary statistics of your dataframes features. It is primarily used with numeric data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: center;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>age</th>\n",
       "      <th>result</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>400.5</td>\n",
       "      <td>0.5825</td>\n",
       "      <td>0.28625</td>\n",
       "      <td>0.32125</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>0.20875</td>\n",
       "      <td>0.27375</td>\n",
       "      <td>0.7175</td>\n",
       "      <td>0.31625</td>\n",
       "      <td>0.46</td>\n",
       "      <td>28.61231</td>\n",
       "      <td>7.05853</td>\n",
       "      <td>0.23125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>231.0844</td>\n",
       "      <td>0.4934553</td>\n",
       "      <td>0.4522904</td>\n",
       "      <td>0.4672487</td>\n",
       "      <td>0.4930303</td>\n",
       "      <td>0.4985021</td>\n",
       "      <td>0.4066696</td>\n",
       "      <td>0.4461611</td>\n",
       "      <td>0.4504969</td>\n",
       "      <td>0.4653027</td>\n",
       "      <td>0.4987092</td>\n",
       "      <td>12.87237</td>\n",
       "      <td>3.788969</td>\n",
       "      <td>0.4218956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.560505</td>\n",
       "      <td>-2.594654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>200.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.28208</td>\n",
       "      <td>4.527556</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>400.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.47996</td>\n",
       "      <td>6.893472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>600.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.15476</td>\n",
       "      <td>9.892981</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.40249</td>\n",
       "      <td>13.39087</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID     A1_Score  A2_Score  A3_Score  A4_Score  A5_Score  A6_Score  A7_Score  A8_Score  A9_Score  A10_Score    age     result   Class/ASD\n",
       "count    800.0     800.0     800.0     800.0     800.0     800.0     800.0     800.0     800.0     800.0     800.0     800.0     800.0     800.0 \n",
       "mean     400.5    0.5825   0.28625   0.32125     0.415    0.4575   0.20875   0.27375    0.7175   0.31625      0.46  28.61231   7.05853   0.23125 \n",
       "std   231.0844 0.4934553 0.4522904 0.4672487 0.4930303 0.4985021 0.4066696 0.4461611 0.4504969 0.4653027 0.4987092  12.87237  3.788969 0.4218956 \n",
       "min        1.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  9.560505 -2.594654       0.0 \n",
       "25%     200.75       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  19.28208  4.527556       0.0 \n",
       "50%      400.5       1.0       0.0       0.0       0.0       0.0       0.0       0.0       1.0       0.0       0.0  25.47996  6.893472       0.0 \n",
       "75%     600.25       1.0       1.0       1.0       1.0       1.0       0.0       1.0       1.0       1.0       1.0  33.15476  9.892981       0.0 \n",
       "max      800.0       1.0       1.0       1.0       1.0       1.0       1.0       1.0       1.0       1.0       1.0  72.40249  13.39087       1.0 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value Counts For All Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "16.69477    1\n",
      "17.89826    1\n",
      "32.16281    1\n",
      "18.00918    1\n",
      "22.42243    1\n",
      "           ..\n",
      "14.25669    1\n",
      "61.03529    1\n",
      "14.67989    1\n",
      "13.82937    1\n",
      "18.6054     1\n",
      "Name: count, Length: 800, dtype: int64\n",
      "gender\n",
      "f    415\n",
      "m    385\n",
      "Name: count, dtype: int64\n",
      "ethnicity\n",
      "White-European     211\n",
      "?                  151\n",
      "Asian              134\n",
      "Middle Eastern     116\n",
      "Black               45\n",
      "Latino              44\n",
      "South Asian         35\n",
      "Others              24\n",
      "Pasifika            18\n",
      "Hispanic            16\n",
      "Turkish              4\n",
      "others               2\n",
      "Name: count, dtype: int64\n",
      "jaundice\n",
      "no     604\n",
      "yes    196\n",
      "Name: count, dtype: int64\n",
      "austim\n",
      "no     683\n",
      "yes    117\n",
      "Name: count, dtype: int64\n",
      "contry_of_res\n",
      "United States           148\n",
      "United Arab Emirates     94\n",
      "New Zealand              93\n",
      "India                    74\n",
      "United Kingdom           58\n",
      "Australia                43\n",
      "Jordan                   40\n",
      "Afghanistan              23\n",
      "Sri Lanka                16\n",
      "Canada                   15\n",
      "Netherlands              14\n",
      "Austria                  12\n",
      "France                   12\n",
      "Italy                    11\n",
      "Brazil                    9\n",
      "Russia                    9\n",
      "Kazakhstan                7\n",
      "Philippines               6\n",
      "Mexico                    6\n",
      "Armenia                   6\n",
      "Viet Nam                  6\n",
      "South Africa              5\n",
      "Spain                     5\n",
      "Malaysia                  5\n",
      "Iran                      5\n",
      "Egypt                     5\n",
      "Nicaragua                 4\n",
      "Costa Rica                4\n",
      "Saudi Arabia              4\n",
      "Bolivia                   3\n",
      "Ukraine                   3\n",
      "Aruba                     3\n",
      "Belgium                   3\n",
      "Bahamas                   3\n",
      "Germany                   3\n",
      "Romania                   3\n",
      "Ethiopia                  3\n",
      "Ireland                   3\n",
      "Czech Republic            3\n",
      "Argentina                 2\n",
      "Pakistan                  2\n",
      "Iceland                   2\n",
      "Azerbaijan                2\n",
      "Serbia                    2\n",
      "Angola                    2\n",
      "China                     2\n",
      "AmericanSamoa             2\n",
      "Japan                     2\n",
      "Sierra Leone              1\n",
      "Indonesia                 1\n",
      "Uruguay                   1\n",
      "Finland                   1\n",
      "Iraq                      1\n",
      "Hong Kong                 1\n",
      "Tonga                     1\n",
      "Cyprus                    1\n",
      "Ecuador                   1\n",
      "Bangladesh                1\n",
      "Oman                      1\n",
      "Sweden                    1\n",
      "Niger                     1\n",
      "Name: count, dtype: int64\n",
      "used_app_before\n",
      "no     765\n",
      "yes     35\n",
      "Name: count, dtype: int64\n",
      "result\n",
      "2.845172    1\n",
      "3.136957    1\n",
      "8.92074     1\n",
      "13.34315    1\n",
      "3.751887    1\n",
      "           ..\n",
      "7.949723    1\n",
      "1.530098    1\n",
      "13.16751    1\n",
      "10.5443     1\n",
      "7.819715    1\n",
      "Name: count, Length: 800, dtype: int64\n",
      "age_desc\n",
      "18 and more    800\n",
      "Name: count, dtype: int64\n",
      "relation\n",
      "Self                        617\n",
      "?                            77\n",
      "Parent                       49\n",
      "Relative                     43\n",
      "Health care professional      7\n",
      "Others                        7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# iterate through the categorical features and return values\n",
    "for feature in df.columns:\n",
    "    if df[feature].dtype != 'int64':\n",
    "        print(df[feature].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Specific Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Check for Target Leakage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. AutoViz\n",
    "\n",
    "AutoViz is an automated vizualisation package that gives a quick interactive overview of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAV = AutoViz_Class()\\n%matplotlib inline \\n\\n# Run AutoViz on the dataframe\\ndft = AV.AutoViz(\\n    \"\",\\n    sep=\",\",\\n    depVar=\"\",\\n    dfte=df,\\n    header=0,\\n    verbose=1,\\n    lowess=False,\\n    chart_format=\"svg\",\\n    max_rows_analyzed=150000,\\n    max_cols_analyzed=30,\\n    save_plot_dir=None\\n)\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "AV = AutoViz_Class()\n",
    "%matplotlib inline \n",
    "\n",
    "# Run AutoViz on the dataframe\n",
    "dft = AV.AutoViz(\n",
    "    \"\",\n",
    "    sep=\",\",\n",
    "    depVar=\"\",\n",
    "    dfte=df,\n",
    "    header=0,\n",
    "    verbose=1,\n",
    "    lowess=False,\n",
    "    chart_format=\"svg\",\n",
    "    max_rows_analyzed=150000,\n",
    "    max_cols_analyzed=30,\n",
    "    save_plot_dir=None\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace/Impute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Yes/No to numeric booleans and standardize \"Others\"\n",
    "df = df.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "base_features = ['<insert list of feature names>']\n",
    "\n",
    "X = df[base_features]\n",
    "\n",
    "y = df.\"<insert column name>\"\n",
    "\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering/Selection\n",
    "\n",
    "* Differencing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. AutoML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Iterative Modeling and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/fifa-2018-match-statistics/FIFA 2018 Statistics.csv')\n",
    "y = (data['Man of the Match'] == \"Yes\")  # Convert from string \"Yes\"/\"No\" to binary\n",
    "feature_names = [i for i in data.columns if data[i].dtype in [np.int64]]\n",
    "X = data[feature_names]\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "my_model = RandomForestClassifier(n_estimators=100,\n",
    "                                  random_state=0).fit(train_X, train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Explainability\n",
    "\n",
    "### 9a. Feature importance\n",
    "\n",
    "<ins>[Permutation importance](https://scikit-learn.org/dev/modules/permutation_importance.html)</ins>: Permutation importance is calculated after a model has been fitted, and involves randomly shuffling a single column of the data set, leaving the target and all other features in place. Then you measure how that affects the accuracy of predictions in that now-shuffled data. The benefits of permutation importance is that it is generally fast to calculate, widely used, and easy to understand. \n",
    "* Shuffling a single feature/column at random should lead to less accurate predictions, since the resulting data set no longer corresponds to anything observed in the real world. Model accuracy especially suffers if we shuffle a column that the model relied on heavily for predictions.\n",
    "* Pro tip: The scale of features does not affect permutation importance per se. The only reason that rescaling a feature could affect PI is indirectly, if rescaling helped or hurt the ability of the particular model you are using to make use of that feature.\n",
    "\n",
    "\n",
    "The high-level process is as follows\n",
    "1. Get a trained model.\n",
    "2. Shuffle the values in a single column, make predictions using the resulting dataset. Use these predictions and the true target values to calculate how much the loss function suffered from shuffling. That performance deterioration measures the importance of the variable you just shuffled.\n",
    "3. Return the data to the original order (undoing the shuffle from step 2). Now repeat step 2 with the next column in the dataset, until you have calculated the importance of each column.\n",
    "4. Interpret your results\n",
    "    * The values towards the top (i.e. the bigger ones) are the most important featues\n",
    "    * The first column shows how much model performance increased/decreased with a random shuffle\n",
    "    * The second column measures the amount of randomness by repeating the process with multiple shuffles. The number after the +- measures performance varied from one-reshuffling to the next\n",
    "    * In the case of negative values, the predictions on the shuffled/noisy data happened to be more accurate than the real data. This happens when the feature didn't matter (should have had an importance close to 0), but random chance caused the predictions on shuffled data to be more accurate. This is more common with small datasets, like the one in this example, because there is more room for luck/chance.\n",
    "\n",
    "**[ELI5 Library](https://pypi.org/project/eli5/)**\n",
    "\n",
    "The below implementation uses the ELI5 library. ELI5 is a Python package which helps users to explain and debug ML classifiers. It can be used with many of the common machine learning frameworks (sklearn, Keras, xgboost, LightGBM, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(my_model, random_state=1).fit(val_X, val_y)\n",
    "eli5.show_weights(perm, feature_names = val_X.columns.tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9b. Partial Dependence Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Lessons Learned"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
