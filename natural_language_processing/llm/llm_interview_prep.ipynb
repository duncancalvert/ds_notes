{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Interview Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğ—”ğ—¿ğ—°ğ—µğ—¶ğ˜ğ—²ğ—°ğ˜ğ˜‚ğ—¿ğ—² & ğ—§ğ—¿ğ—®ğ—¶ğ—»ğ—¶ğ—»ğ—´\n",
    "\n",
    "### Transformer Architecture (attention mechanisms\n",
    "\n",
    "### Pre-training vs Fine-tuning\n",
    "\n",
    "### Training Objectives (next token prediction)\n",
    "\n",
    "### Context Window and Position Embeddings\n",
    "\n",
    "### Tokenization Strategies\n",
    "\n",
    "### Model Scaling Laws\n",
    "\n",
    "### Parameter Efficient Fine-tuning (LoRA, QLoRA, Prefix Tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğ—šğ—²ğ—»ğ—²ğ—¿ğ—®ğ˜ğ—¶ğ—¼ğ—» ğ—–ğ—¼ğ—»ğ˜ğ—¿ğ—¼ğ—¹\n",
    "\n",
    "### Temperature and Top-p Sampling\n",
    "\n",
    "### Prompt Engineering Techniques\n",
    "\n",
    "### Few-shot Learning\n",
    "\n",
    "### In-context Learning\n",
    "\n",
    "### Chain-of-Thought Prompting\n",
    "\n",
    "### Hallucination Mitigation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğ—Ÿğ—Ÿğ—  ğ—˜ğ˜ƒğ—®ğ—¹ğ˜‚ğ—®ğ˜ğ—¶ğ—¼ğ—»\n",
    "\n",
    "### Perplexity\n",
    "\n",
    "### ROUGE Scores\n",
    "\n",
    "### BLEU Scores\n",
    "\n",
    "### Human Evaluation Methods\n",
    "\n",
    "### Benchmark Datasets (MMLU, BigBench, HumanEval)\n",
    "\n",
    "### Bias Detection\n",
    "\n",
    "### LLM-as-a-judge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğ—¢ğ—½ğ˜ğ—¶ğ—ºğ—¶ğ˜‡ğ—®ğ˜ğ—¶ğ—¼ğ—» & ğ——ğ—²ğ—½ğ—¹ğ—¼ğ˜†ğ—ºğ—²ğ—»ğ˜\n",
    "\n",
    "### Quantization Techniques (4-bit, 8-bit)\n",
    "\n",
    "### Model Distillation\n",
    "\n",
    "### Prompt Caching\n",
    "\n",
    "### Model Merging\n",
    "\n",
    "### Inference Optimization\n",
    "\n",
    "### Load Balancing\n",
    "\n",
    "### Latency Management\n",
    "\n",
    "### Cost Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğ—¦ğ—®ğ—³ğ—²ğ˜ğ˜† & ğ—˜ğ˜ğ—µğ—¶ğ—°ğ˜€\n",
    "\n",
    "### Content Filtering\n",
    "\n",
    "### Output Sanitization\n",
    "\n",
    "### Jailbreak Prevention\n",
    "\n",
    "### Data Privacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieval Augmented Generation (RAG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Product Sense - Good vs. Bad LLM Use Cases\n",
    "\n",
    "### Good LLM Use Cases\n",
    "\n",
    "### Bad LLM Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
